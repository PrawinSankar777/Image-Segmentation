{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrawinSankar777/Image-Segmentation/blob/master/unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Jnxl75buin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNk0fsqKokp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rsync -av /content/drive/My\\ Drive/agv/Stage_1 /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvA72P5NopjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf Agriculture-Vision.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qczoQe53r1Hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/agv/Stage_1/Lables/planter_skip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZLvTumlosKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -1 | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy0ZUrwmul_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tifffile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZlUZ3Y_f5P3",
        "colab_type": "text"
      },
      "source": [
        "Data sorting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ4vlRS7f5r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv `ls | head -680` /content/Stage_1/Lables/weed_cluster"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOBN2deRrBeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rsync -av /content/Stage_1 /content/drive/My\\ Drive/agv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l70hYK6sjce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv *tif /content/Stage_1/NDVI_Images/weed_cluster"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiNdMeRcxX0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/Stage_1 /content/drive/My\\ Drive/agv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAdnmhI4t0F_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"/content/Agriculture-Vision/train/labels/cloud_shadow\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nauvmKRLTDSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tifffile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0fgqoKAmM-L",
        "colab_type": "text"
      },
      "source": [
        "Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsWcxrRXbIp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tifffile as tff\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "## Seeding \n",
        "seed = 2019\n",
        "random.seed = seed\n",
        "np.random.seed = seed\n",
        "tf.seed = seed\n",
        "\n",
        "train_dir = \"/content/drive/My Drive/agv/S1\"\n",
        "train_ids = next(os.walk(train_dir))[1]\n",
        "img_size = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_hE2qVupa9T",
        "colab_type": "text"
      },
      "source": [
        "Datagen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8pSVjMFmSaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGen(keras.utils.Sequence):\n",
        "    def __init__(self, ids, path, batch_size, image_size):\n",
        "        self.ids = ids\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __load__(self, id_name):\n",
        "        ## Path\n",
        "        image_path = os.path.join(self.path, id_name, \"image\", id_name) + \".tif\"\n",
        "        mask_path = os.path.join(self.path, id_name, \"mask/\")\n",
        "        all_masks = os.listdir(mask_path)\n",
        "        \n",
        "        ## Reading Image\n",
        "        image = tff.imread(image_path)\n",
        "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "        \n",
        "        mask = np.zeros((self.image_size, self.image_size, 1))\n",
        "        \n",
        "        ## Reading Masks\n",
        "        for name in all_masks:\n",
        "            _mask_path = mask_path + name\n",
        "            _mask_image = cv2.imread(_mask_path, -1)\n",
        "            _mask_image = cv2.resize(_mask_image, (self.image_size, self.image_size)) #128x128\n",
        "            _mask_image = np.expand_dims(_mask_image, axis=-1)\n",
        "            mask = np.maximum(mask, _mask_image)\n",
        "            \n",
        "        ## Normalizaing \n",
        "        image = image/255.0\n",
        "        mask = mask/255.0\n",
        "        \n",
        "        return image, mask\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if(index+1)*self.batch_size > len(self.ids):\n",
        "            self.batch_size = len(self.ids) - index*self.batch_size\n",
        "        \n",
        "        files_batch = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n",
        "        \n",
        "        image = []\n",
        "        mask  = []\n",
        "        \n",
        "        for id_name in files_batch:\n",
        "            _img, _mask = self.__load__(id_name)\n",
        "            image.append(_img)\n",
        "            mask.append(_mask)\n",
        "            \n",
        "        image = np.array(image)\n",
        "        mask  = np.array(mask)\n",
        "        image = np.expand_dims(image,axis=3)\n",
        "        \n",
        "        return image, mask\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.ids)/float(self.batch_size)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESXQy4U5MMDT",
        "colab_type": "text"
      },
      "source": [
        "IOU Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OgKqBR5MMq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4pwk8XEj8fE",
        "colab_type": "text"
      },
      "source": [
        "Convolutional blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEXlpyA7j80i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
        "    return c, p\n",
        "\n",
        "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
        "    concat = keras.layers.Concatenate()([us, skip])\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c\n",
        "\n",
        "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is7Lr2LMkCkl",
        "colab_type": "text"
      },
      "source": [
        "U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td13Ydw6kC9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def UNet():\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = keras.layers.Input((img_size, img_size, 1))\n",
        "    \n",
        "    p0 = inputs\n",
        "    c1, p1 = down_block(p0, f[0]) #128 -> 64\n",
        "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
        "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
        "    c4, p4 = down_block(p3, f[3]) #16->8\n",
        "    \n",
        "    bn = bottleneck(p4, f[4])\n",
        "    \n",
        "    u1 = up_block(bn, c4, f[3]) #8 -> 16\n",
        "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
        "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
        "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
        "    \n",
        "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
        "    model = keras.models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwrqrLjLkJKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = UNet()\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[mean_iou])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iRnhpttQXzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ids = next(os.walk(train_dir))[1]\n",
        "\n",
        "## Validation Data Size\n",
        "val_data_size = 36\n",
        "\n",
        "valid_ids = train_ids[:val_data_size]\n",
        "train_ids = train_ids[val_data_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i0whYuuYcFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen = DataGen(train_ids, train_dir, image_size=img_size, batch_size=20)\n",
        "valid_gen = DataGen(valid_ids, train_dir, image_size=img_size, batch_size=5)\n",
        "epochs = 10\n",
        "model.fit_generator(train_gen, validation_data=valid_gen, steps_per_epoch=10, validation_steps=3, \n",
        "                    epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}